# -*- coding: utf-8 -*-
"""UAVTF_Models_1

Automatically generated by Colaboratory.

"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
print("Tensorflow version " + tf.__version__)

try:
  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection
  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])
except ValueError:
  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')

tf.config.experimental_connect_to_cluster(tpu)
tf.tpu.experimental.initialize_tpu_system(tpu)
tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)


import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.regularizers import l2
from sklearn.model_selection import train_test_split, KFold
import pandas as pd
import numpy as np
import cv2
from PIL import Image
from natsort import natsorted, ns 
import glob
from tqdm.notebook import tqdm
import os
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import metrics 
from sklearn.metrics import classification_report

from tensorflow.python.client import  device_lib
device_lib.list_local_devices()

from google.colab import drive
drive.mount('/content/drive')

import h5py
 
DATA_DIR = "/content/drive/MyDrive/data_224.mat"

data = h5py.File(DATA_DIR,'r')
 
data.keys()

import numpy as np

X = np.transpose(np.array(data['Img_Data_Res']))
# np.save('/content/drive/MyDrive/data_array.npy',X) 
Y = np.reshape(np.array(data['Labels']),[-1,])
 
print(X.shape)
print(Y.shape)

# X = np.load('/content/drive/MyDrive/data_array.npy')
# Y = np.reshape(np.array(data['Labels']),[-1,])

# print(X.shape)
# print(Y.shape)

# def get_arrays():
#   X = []
#   Y = []
#   datapath = "/content/drive/MyDrive/WSST_Final"
#   datapath_list = sorted(os.listdir(datapath))
#   i = 0
#   for subdir in datapath_list:
#     if i>14:  #15 is the number of classes
#       break
#     subdir_path = os.path.join(datapath, subdir)
#     subdir_path = os.path.join(subdir_path, '*g')
#     files = glob.glob(subdir_path)
#     files = natsorted(files, key = lambda x: x.lower()) #Ascending sort
#     for f in tqdm(files):
#       np_img = np.asarray(Image.open(f).resize((224,224)))
#       np_img_new = np_img/255
#       X.append(np_img_new)
#       Y.append(i) 
#     i = i+1
#   X = np.asarray(X)
#   Y = np.asarray(Y)
#   return X, Y

# X,Y = get_arrays()

X, X_test, Y, Y_test = train_test_split(X, Y, test_size=0.1)
# X = (X/255.0).astype(np.float16)
# X_test = (X_test/255.0).astype(np.float16)

print(X.shape)
print(Y.shape)



def create_model():
  base_model = tf.keras.applications.EfficientNetB7( weights="imagenet",include_top=False,
  input_tensor=None,classes=15,input_shape=(224, 224, 3))
  base  _model.trainable = False
  inputs = keras.Input(shape=(224, 224, 3))
  # x = keras.layers.BatchNormalization()(inputs)
  x = base_model(inputs, training=False)
  x = keras.layers.GlobalAveragePooling2D()(x)    
  #x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout
  outputs = keras.layers.Dense(15, activation='softmax')(x)
  model = keras.Model(inputs, outputs)
  return model


train_accuracy_per_fold = []
test_accuracy_per_fold = []
kfold = KFold(n_splits = 10, shuffle=True)
fold = 1
for train, test in kfold.split(X,Y):


  with tpu_strategy.scope():
    model = create_model()
    classifier.compile(loss = tf.keras.losses.sparse_categorical_crossentropy, 
   optimizer = tf.keras.optimizers.Adam(), metrics = ['accuracy'])


  history = classifier.fit(X[train], Y[train], epochs =30, shuffle = True,batch_size = 128,
                    validation_split=0.10, use_multiprocessing = True)

  # early_stopping_split = tf.keras.callbacks.EarlyStopping(
  #   monitor = "val_loss",
  #   patience = 20
  # )
  test_loss, test_acc = model.evaluate(X_test, Y_test, verbose = 2)
  print("Test accuracy in fold {} : {}%".format(fold, test_acc*100))
  fold = fold+1
  test_accuracy_per_fold.append(test_acc*100)
print(f'> Overall Test Accuracy: {np.mean(test_accuracy_per_fold)} (+- {np.std(test_accuracy_per_fold)})')

with tpu_strategy.scope():
  model = create_model()
optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)
model.compile(
      optimizer = optimizer, loss = "sparse_categorical_crossentropy", metrics = ["accuracy"]
)

# early_stopping_split = tf.keras.callbacks.EarlyStopping(
#   monitor = "val_loss",
#   patience = 20
# )

history = model.fit(X, Y, epochs = 30, batch_size=128, shuffle = True, validation_split = 0.1)
test_loss, test_acc = model.evaluate(X_test, Y_test, verbose = 2)

model.summary()

model.save('/content/drive/MyDrive/UAV_Models/efficientnetb7.h5')

